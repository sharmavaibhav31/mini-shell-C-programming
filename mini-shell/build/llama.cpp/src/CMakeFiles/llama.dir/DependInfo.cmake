
# Consider dependencies only in project.
set(CMAKE_DEPENDS_IN_PROJECT_ONLY OFF)

# The set of languages for which implicit dependencies are needed:
set(CMAKE_DEPENDS_LANGUAGES
  )

# The set of dependency files which are needed:
set(CMAKE_DEPENDS_DEPENDENCY_FILES
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/llama-adapter.cpp" "llama.cpp/src/CMakeFiles/llama.dir/llama-adapter.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/llama-adapter.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/llama-arch.cpp" "llama.cpp/src/CMakeFiles/llama.dir/llama-arch.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/llama-arch.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/llama-batch.cpp" "llama.cpp/src/CMakeFiles/llama.dir/llama-batch.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/llama-batch.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/llama-chat.cpp" "llama.cpp/src/CMakeFiles/llama.dir/llama-chat.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/llama-chat.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/llama-context.cpp" "llama.cpp/src/CMakeFiles/llama.dir/llama-context.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/llama-context.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/llama-cparams.cpp" "llama.cpp/src/CMakeFiles/llama.dir/llama-cparams.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/llama-cparams.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/llama-grammar.cpp" "llama.cpp/src/CMakeFiles/llama.dir/llama-grammar.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/llama-grammar.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/llama-graph.cpp" "llama.cpp/src/CMakeFiles/llama.dir/llama-graph.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/llama-graph.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/llama-hparams.cpp" "llama.cpp/src/CMakeFiles/llama.dir/llama-hparams.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/llama-hparams.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/llama-impl.cpp" "llama.cpp/src/CMakeFiles/llama.dir/llama-impl.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/llama-impl.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/llama-io.cpp" "llama.cpp/src/CMakeFiles/llama.dir/llama-io.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/llama-io.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/llama-kv-cache-iswa.cpp" "llama.cpp/src/CMakeFiles/llama.dir/llama-kv-cache-iswa.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/llama-kv-cache-iswa.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/llama-kv-cache.cpp" "llama.cpp/src/CMakeFiles/llama.dir/llama-kv-cache.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/llama-kv-cache.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/llama-memory-hybrid.cpp" "llama.cpp/src/CMakeFiles/llama.dir/llama-memory-hybrid.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/llama-memory-hybrid.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/llama-memory-recurrent.cpp" "llama.cpp/src/CMakeFiles/llama.dir/llama-memory-recurrent.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/llama-memory-recurrent.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/llama-memory.cpp" "llama.cpp/src/CMakeFiles/llama.dir/llama-memory.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/llama-memory.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/llama-mmap.cpp" "llama.cpp/src/CMakeFiles/llama.dir/llama-mmap.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/llama-mmap.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/llama-model-loader.cpp" "llama.cpp/src/CMakeFiles/llama.dir/llama-model-loader.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/llama-model-loader.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/llama-model-saver.cpp" "llama.cpp/src/CMakeFiles/llama.dir/llama-model-saver.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/llama-model-saver.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/llama-model.cpp" "llama.cpp/src/CMakeFiles/llama.dir/llama-model.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/llama-model.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/llama-quant.cpp" "llama.cpp/src/CMakeFiles/llama.dir/llama-quant.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/llama-quant.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/llama-sampling.cpp" "llama.cpp/src/CMakeFiles/llama.dir/llama-sampling.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/llama-sampling.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/llama-vocab.cpp" "llama.cpp/src/CMakeFiles/llama.dir/llama-vocab.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/llama-vocab.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/llama.cpp" "llama.cpp/src/CMakeFiles/llama.dir/llama.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/llama.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/unicode-data.cpp" "llama.cpp/src/CMakeFiles/llama.dir/unicode-data.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/unicode-data.cpp.o.d"
  "/home/vaibhav/Documents/C_project/mini-shell/llama.cpp/src/unicode.cpp" "llama.cpp/src/CMakeFiles/llama.dir/unicode.cpp.o" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/unicode.cpp.o.d"
  "" "bin/libllama.so" "gcc" "llama.cpp/src/CMakeFiles/llama.dir/link.d"
  )

# Targets to which this target links which contain Fortran sources.
set(CMAKE_Fortran_TARGET_LINKED_INFO_FILES
  )

# Targets to which this target links which contain Fortran sources.
set(CMAKE_Fortran_TARGET_FORWARD_LINKED_INFO_FILES
  )

# Fortran module output directory.
set(CMAKE_Fortran_TARGET_MODULE_DIR "")
